{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [2, 2] # inches\n",
    "mpl.rcParams['font.size'] = 8\n",
    "\n",
    "# Define a function to do the most common plotting task\n",
    "def xyplot(x1=None, y1=None, x2=None, y2=None, x3=None, y3=None, title=None, fname=None):\n",
    "    plt.figure()\n",
    "    if x1 is not None and y1 is not None:\n",
    "        plt.plot(x1,y1,'b.')\n",
    "    if x2 is not None and y2 is not None:\n",
    "        plt.plot(x2,y2,'k-')\n",
    "    if x3 is not None and y3 is not None:\n",
    "        plt.plot(x3,y3,'r-')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if fname:\n",
    "        plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a simple linear model with some noise added. We plot the underlying trend (black line) and also the data points (blue). The random seed is set explicitly so that the graph can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmczuX+x/HXx9KpU0qn6FQqnY7s2SZMWmwVosRRCSF+Dkelk7XsyxhbSH6UEyEkRUmphCYtirFm156QLVuWYebz+2OmTvkRMff9vZf38/GYxz1z37f7es99OvOe6/pe8/2auyMiIhJpcgQdQERE5HhUUCIiEpFUUCIiEpFUUCIiEpFUUCIiEpFUUCIiEpFUUCIiEpFUUCIiEpFUUCIBMLNJZrbFzPaa2QYzaxni8f5kZmPN7Bsz22dmy8ysZijHFDlTKiiRYCQDBd39fOBOoJ+ZlTvdFzOzXmbW63eekgv4DrgFuADoDkwzs4KnO6ZIqKmgRE7AzM4zs3Qzu/RX95XImvnkOZPXdvfV7n745y+zPq7JGmOQmb36qzEHm9k8M8t9BuP95O693P1rd89w9zeAr4DTLkWRUFNBiZyAu+8H1gFlf3X3AKC/u+/7+Q4ze8PMdp/g440Tvb6ZjTKzA1ljbAFmZz00EKhiZqXNrDVQA6jn7key63szs0uAa4HV2fWaItktV9ABRCLcYjIL6k0zuxkoBtT79RPcvfbpvLC7/8vMHgYSgcrA4az7d5rZcGAimctxN7r7ntP+Do6RNRObDExw93XZ9boi2U0zKJHf93NBAQwCurt7Wna9uLunu/uHQAGgza8eWgaUBB539++O929/PXMDugBdTjZzM7McwAtAGvBQdn0fIqGgghL5fYuBsmZWHzgHePHYJ5jZW2a2/wQfb53iOLn47zGoksBoYALw4In+gbvXdve87p6XzKXHAT9/fbxZnZkZMBa4BKifnUuGIqGgJT6R37cC+CvwJNDG3TOOfYK7/6Ht2maWH6gKvAEcBKoDDYH7zexyYBbQGpgLfGVmld095Uy+iSyjgaJAdXc/mA2vJxJSmkGJ/I6snXafAV+7+6nOhk76smQu520CfgSGAI8C75G5UWKou7/u7geAwUDSmQ5oZlcB/wRKA1t/NcNrdKavLRIqpivqipyYmZ0FfA7c4+6fBJ1HJJ5oBiXy+3oCH6mcRMJPBSVyHGZW1sz2ADcDDwedRyQeaYlPREQikmZQIiISkaJim/nFF1/sBQsWDDqGiIhkgyVLluxw93wne15UFFTBggVJTU0NOoaIiGQDM/vmVJ6nJT4REYlIKigREYlIKigREYlIKigREYlIKigREYlIKigREYlIKigREYlIKigRETkly5YtY9y4cWEbTwUlIiK/65tvvuGBBx6gXLlydO/enUOHDoVlXBWUiIgc1+7du+nUqROFCxdm2rRpNGrUiRYtVrNs2dlhGT8qTnUkIiLhc/jwYUaPHk3fvn358ccfadKkCXXr9qVRoytJS4MhQ2DePEhMDG0OzaBERAQAd2fq1KkULVqUf//735QrV46lS5cyYcIE1q3LLKf0dEhLg5SU0OdRQYmICO+//z4VKlSgYcOG5MmTh3feeYc5c+ZQunRpACpXhrPOgpw5M28rVw59Ji3xiYjEsTVr1tClSxdmzZpFgQIFGD9+PI0bNyZnzpy/eV5iYuayXkpKZjmFenkPVFAiInFpy5Yt9OrVi+eee47zzjuP5ORk2rVrxznnnHPCf5OYGJ5i+pkKSkQkjuzfv58hQ4YwZMgQDh8+zEMPPUS3bt3Il++k1w8MOxWUiEgcOHr0KGPHjqVnz5788MMPNGjQgP79+/P3v/896GgnpIISEYlh7s6sWbPo3Lkz69ato1KlSrz22mtUrFgx6GgnFbJdfGY2zsy2mdmqY+5/2MzWm9lqMxsUqvFFROLdokWLqFy5MnfddRcZGRm8+uqrfPDBB1FRThDabebjgRq/vsPMqgB3Ade5e3FgSAjHFxGJS1988QX33nsvFSpUYN26dYwaNYpVq1ZRt25dzCzoeKcsZEt87r7AzAoec3cbYIC7H856zrZQjS8iEm927txJ3759GTVqFLlz56Z79+507NiRPHnyBB3ttIT7D3WvBW4ys0/N7H0zu/5ETzSzVmaWamap27dvD2NEEZHocvDgQQYOHMg111zD008/TdOmTdm4cSN9+vSJ2nKC8BdULuBCoCLQEZhmJ5hvuvsYd09w94RI3P4oIhK0jIwMJk6cSOHChenSpQs33XQTK1eu5D//+Q+XXXZZ0PHOWLgLahMwwzMtAjKAi8OcQUQk6r377ruULVuWpk2bkj9/fubPn8+sWbMoXrx40NGyTbgL6jWgKoCZXQucBewIcwYRkai1YsUKatSowW233caePXuYMmUKixYtokqVKkFHy3ah3Gb+IrAQKGxmm8ysBTAO+FvW1vOpQFN391BlEBGJFZs2baJZs2aUKVOGRYsW8eSTT7Ju3ToaNmxIjhyxed7vUO7ia3iChxqHakwRkVizZ88eBg4cyLBhw8jIyKB9+/Y88cQTXHjhhUFHCzmdSUJEJAKlpaXxzDPP0KdPH3bu3EmjRo3o168fBQsWDDpa2MTmvFBEJEq5Oy+//DLFihWjXbt2lCpViiVLljBp0qS4KidQQYmIRIwPP/yQxMRE7rnnHs455xxmz57N3LlzKVu2bNDRAqGCEhE5gYULITk58zaU1q9fz913381NN93Ed999x9ixY1m+fDk1a9aMqlMTZTcdgxIROY6FC6FaNUhLy7zE+bx52X+xvh9++IHevXszZswY/vznP9OvXz8effRRzj333OwdKEqpoEREjiMlJbOc0tMzb1NSsq+gfvrpJ4YOHcqgQYM4dOgQrVu3pkePHuTPnz97BogRKigRkeOoXDlz5vTzDKpy5TN/zaNHjzJ+/Hh69OjBli1bqFevHsnJyVx77bVn/uIxSAUlInIciYmZy3opKZnldCazJ3dn9uzZdO7cmdWrV5OYmMjLL79MpUqVsituTFJBiYicQGLimS/rpaam0rFjR1JSUihUqBDTp0/n7rvvjuvND6dKu/hERELgq6++4v777+f6669n1apVjBw5ktWrV1OvXj2V0ynSDEpEJBvt2rWLpKQkRo4cSc6cOenatSudOnXi/PPPDzpa1FFBiYhkg0OHDjFy5EiSkpLYs2cPzZs3p3fv3hQoUCDoaFFLS3wiImcgIyODyZMnU6RIETp27EhiYiIrVqxg7NixKqczpIISETlN8+fP5/rrr6dx48b85S9/Ye7cucyePZuSJUsGHS0mqKBERP6gVatWUatWLapVq8aOHTt44YUXSE1NpVq1akFHiymhvGDhODPblnVxwmMf62Bmbma63LuIRI3vv/+eli1bUqpUKRYuXMjgwYNZv349jRs3jtmLBgYplO/oeKDGsXea2RXArcC3IRxbRCTb7N27l27dulGoUCEmTpxIu3bt+Pzzz+nQoQNnn3120PFiVsgKyt0XALuO89AwoBOgS72LSEQ7cuQIo0aN4u9//ztJSUnUrVuX9evXM3ToUC666KKg48W8sM5JzexO4Ht3XxHOcUVE/gh3Z8aMGRQvXpy2bdtSrFgxFi1axJQpU7j66quDjhc3wlZQZvZnoCvQ4xSf38rMUs0sdfv27aENJyKS5eOPP+bGG2+kfv365MqVi9dff5333nuP66+/PuhocSecM6hrgKuBFWb2NVAAWGpmfz3ek919jLsnuHtCvnz5whhTROLRxo0b+cc//kGlSpX48ssvGTNmDCtXrqROnTo6NVFAwnYmCXf/DPjlYidZJZXg7jvClUFE5Fjbt2+nT58+PPPMM/zpT3+id+/etG/fXhcNjAAhKygzexGoDFxsZpuAnu4+NlTjiYj8EQcOHGD48OEMGDCAAwcO8D//8z/06tWLSy65JOhokiVkBeXuDU/yeMFQjS0iciLp6elMmDCB7t27s3nzZu666y4GDBhAkSJFgo4mx9BflolIXHB33n77bcqUKUOLFi244oorWLBgAa+99prKKUKpoEQk5i1dupRbb72VmjVrcuDAAaZNm8bChQu56aabgo4mv0MFJSIx65tvvqFJkyaUK1eO5cuX89RTT7FmzRoaNGignXlRQNeDEpGY8+OPP5KcnMyIESMwM7p06ULnzp3Jmzdv0NHkD1BBiUjMOHz4MKNGjaJfv378+OOPPPDAA/Tt25crrrgi6GhyGrTEJyJRLyMjg6lTp1K0aFEee+wxEhISWLp0KePHj1c5RTEVlIhEtffff5+KFSvSsGFD8uTJwzvvvMM777xD6dKlg44mZ0gFJSJRac2aNdSpU4fKlSuzZcsWxo8fz9KlS7ntttuCjibZRAUlIlFly5YttGrVipIlS7JgwQKSk5PZsGEDTZs2JWfOnEHHk2ykTRIi8ouFCyElBSpXhsTEoNP81v79+xk8eDBDhgzhyJEjPPzww3Tr1o2LL9aFuWOVCkpEgMxyqlYN0tLgrLNg3rzIKKmjR4/y3HPP0atXL3744QcaNGhAcnIy11xzTdDRJMS0xCciQObMKS0N0tMzb1NSgs3j7sycOZMSJUrQpk0bChUqxCeffMK0adNUTnFCBSUiQOay3llnQc6cmbeVKweX5dNPP+WWW26hbt26ALz22mssWLCAChUqBBdKwk5LfCICZC7nzZsX7DGoL774gieeeIJp06aRP39+Ro8eTcuWLcmVSz+q4pH+VxeRXyQmBlNMO3bsoF+/fowaNYrcuXPTo0cPOnToQJ48ecIfRiKGCkpEAnPw4EFGjBhB//792b9/Py1atKB3795ceumlQUeTCBCyY1BmNs7MtpnZql/dN9jM1pnZSjN71cx05kaROJSens7EiRMpXLgwXbp04eabb+azzz5jzJgxKif5RSg3SYwHahxz37tACXe/DtgAPB7C8UUkAs2ZM4dy5crRtGlTLrnkEt577z1mzZpFsWLFgo4mESZkBeXuC4Bdx9w3x92PZn35CVAgVOOLSGRZsWIFt99+O7fffjt79uzhxRdf5NNPP6VykNsFJaIFuc38QeCtEz1oZq3MLNXMUrdv3x7GWCKSnb777juaNWtGmTJlWLx4MUOHDmXdunXcd9995Mihv3SREwtkk4SZdQWOApNP9Bx3HwOMAUhISPAwRRORbLJnzx4GDBjA8OHDcXc6dOjA448/zoUXXhh0NIkSYS8oM2sK1AaqubuKRyTGpKWl8cwzz9CnTx927txJ48aN6devH1dddVXQ0STKhHV+bWY1gM7Ane5+IJxji0houTsvv/wyxYoVo127dpQqVYolS5bwwgsvqJzktIRym/mLwEKgsJltMrMWwEggD/CumS03s2dCNb6IhM8HH3xAYmIi99xzD+eccw6zZ89m7ty5lC1bNuhoEsVCtsTn7g2Pc/fYUI0nIuG3bt06unTpwsyZM7nssssYO3asrssk2UZbaETkD9u6dStt2rShRIkSzJ8/n6SkJDZu3MiDDz6ocpJso1Mdicgp++mnn3jyyScZNGgQhw8fpnXr1vTo0YP8+fMHHU1ikApKRE7q6NGjPP/88/To0YOtW7dSv359+vfvz7XXXht0NIlhKigROSF3580336Rz586sWbOGxMREpk+fzg033BB0NIkDOgYlIseVmppK1apVqVOnDkeOHGH69Ol89NFHKicJGxWUiPzGV199RcOGDbn++utZvXo1I0eOZPXq1dSrVw8zCzqexBEt8YkIALt27SIpKYmRI0eSM2dOunbtSqdOnTj//PODjiZxSgUlEucOHTrE008/Tf/+/dmzZw/NmjWjb9++XH755UFHkzinJT6ROJWRkcGkSZMoXLgwnTp1IjExkRUrVjBu3DiVk0QEFZRIHJo3bx4JCQk0adKEiy66iLlz5zJ79mxKliwZdDSRX6igROLIZ599Rq1atahevTo7d+5k0qRJpKamUq1ataCjifw/KiiROPD999/TokULSpcuzcKFCxk8eDDr16+nUaNGumigRCxtkhCJYXv37mXQoEEMHTqU9PR0Hn30UZ544gkuuuiioKOJnJQKSiQGHTlyhDFjxtC7d2+2b99Ow4YNSUpK4uqrrw46msgp09xeJIa4OzNmzKB48eI89NBDFC9enMWLFzNlyhSVk0QdFZRIjPj444+58cYbqV+/Prlz5+aNN95g/vz5JCQkBB1N5LSE8oq648xsm5mt+tV9fzGzd81sY9bthaEaXyRebNiwgfr161OpUiW++uor/vOf/7BixQruuOMOnZpIolooZ1DjgRrH3NcFmOfuhYB5WV+LyGnYtm3bL8t4c+bMoU+fPmzcuJGWLVuSK5cOL0v0C+Ul3xeYWcFj7r4LqJz1+QQgBegcqgwisejAgQMMGzaMgQMHcuDAAVq1akXPnj255JJLgo4mkq3C/WvWJe6+BcDdt5jZCS/DaWatgFYAV155ZZjiiUSu9PR0JkyYQPfu3dm8eTN169YlOTmZIkWKBB1NJCQidpOEu49x9wR3T8iXL1/QcUQC4+689dZblC5dmhYtWnDFFVewYMECXn31VZWTxLRwF9QPZnYpQNbttjCPLxJVli5dSvXq1alVqxYHDx5k2rRpLFy4kJtuuinoaCIhF+6Ceh1omvV5U2BmmMcXiQrffPMNTZo0oVy5cqxYsYIRI0awZs0aGjRooJ15EjdCdgzKzF4kc0PExWa2CegJDACmmVkL4FugQajGF4lGP/74I/3792fEiBHkyJGDxx9/nM6dO3PBBRcEHU0k7EK5i6/hCR7SaZNFjnH48GH+93//l379+rF7926aNm1Knz59uOKKK4KOJhKYiN0kIRIPMjIyePHFFylSpAjt27enfPnyLFu2jOeff17lJHFPBSUSkJSUFCpUqMD999/PBRdcwJw5c3j77bcpVapU0NFEIoIKSiTM1qxZQ506dahSpQo//PADEyZMYOnSpdx6661BRxOJKCookTDZsmULrVq1omTJkixYsIABAwawfv16HnjgAV00UOQ4dMIukRDbt28fQ4YMYciQIRw5coSHH36Ybt26cfHFFwcdTSSinfTXNjN7SGcdF/njjhw5wjPPPEOhQoXo06cPtWvXZu3atQwfPlzlJHIKTmVd4a/AYjObZmY1TH8lKPK73J2ZM2dSsmRJ2rRpw7XXXssnn3zCSy+9xDXXXBN0PJGocdKCcvduQCFgLNAM2Ghm/c1M/08TOcann37KLbfcQt26dTEzZs6cyfvvv0+FChWCjiYSdU7pyKy7O7A16+MocCHwipkNCmE2kajxxRdfcM8991CxYkU2bNjAM888w2effcadd96pUxOJnKaTbpIws0fIPG/eDuA5oKO7HzGzHMBGoFNoI4pErh07dtC3b19Gjx5N7ty56dmzJx06dOC8884LOppI1DuVXXwXA/Xc/Ztf3+nuGWZWOzSxRCLbwYMHeeqpp0hOTmb//v20bNmSXr16cemllwYdTSRmnLSg3L3H7zy2NnvjiES29PR0Jk2aRLdu3di0aRN16tRh4MCBFC1aNOhoIjFHfx0ocormzJlDuXLlaNasGZdeeikpKSm8/vrrKieREFFBiZzEihUruP3227n99tvZu3cvU6dO5ZNPPuGWW24JOppITFNBiZzAd999R9OmTSlTpgypqakMGzaMtWvXcu+99+rURCJhoFMdiRxjz549JCcn89RTT+HudOzYkccff5y8efMGHU0krgRSUGb2b6Al4MBnQHN3PxREFpGfpaWlMXr0aPr27cuuXbto3Lgxffv25aqrrgo6mkhcCvs6hZldDjwCJLh7CSAncF+4c4j8zN2ZNm0aRYsW5dFHH6V06dIsWbKEiRMnqpxEAhTUQnou4BwzywX8GdgcUA6Jcx988AGJiYnce++9nHvuubz99tu8++67lClTJuhoInEv7AXl7t8DQ4BvgS3AHnefc+zzzKyVmaWaWer27dvDHVNi3Lp166hbty4333wzmzZtYty4cSxbtozbb79dpyYSiRBBLPFdCNwFXA1cBpxrZo2PfZ67j3H3BHdPyJcvX7hjSozaunUrbdq0oUSJEsyfP5/+/fuzYcMGmjdvTs6cOYOOJyK/EsQmierAV+6+HcDMZgA3AJMCyCJxYv/+/QwdOpRBgwZx+PBh/vWvf9G9e3f0y49I5AqioL4FKprZn4GDQDUgNYAcEgeOHj3K888/T48ePdi6dSv/+Mc/6N+/P4UKFQo6moicRNgLyt0/NbNXgKVkXrpjGTAm3Dkktrk7b775Jp07d2bNmjVUqlSJGTNmkJiYGHQ0ETlFgezic/ee7l7E3Uu4exN3PxxEjni1cCEkJ2fexqLFixdTpUoV6tSpw9GjR5kxY8Yvu/VEJHroTBJxZuFCqFYN0tLgrLNg3jyIlZ/bX375JV27dmXq1Knkz5+fUaNG0bJlS3Lnzh10NBE5DTqhWJxJScksp/T0zNuUlKATnbmdO3fy2GOPUaRIEWbOnEm3bt34/PPPadOmjcpJJIppBhVnKlfOnDn9PIOqXDnoRKfv0KFDPP300yQlJbFv3z4efPBBevfuzWWXXRZ0NBHJBiqoOJOYmLmsl5KSWU7RuLyXkZHBlClT6Nq1K99++y21atVi4MCBlChRIuhoIpKNVFBxKDExOosJYN68eXTs2JFly5ZRtmxZnn/+eapWrRp0LBEJAR2Dkqjw2WefUbNmTapXr86uXbuYPHkyixcvzpZyivVdjSLRSjMoiWjff/893bt3Z/z48VxwwQUMGTKEtm3bcvbZZ2fL68fyrkaRaKcZlESkvXv30rVrVwoVKsTkyZN57LHH+OKLL2jfvn22lRPE5q5GkVihGZRElCNHjvDss8/Su3dvduzYwf33309SUhIFCxYMyXixtKtRJNaooCQiuDszZszg8ccfZ+PGjVSpUoXBgwdTrly5kI4bC7saRWKVCkoC9/HHH9OhQwcWLlxI8eLFefPNN6lZs2bYrssUzbsaRWKZjkFJYDZs2ED9+vWpVKkSX3/9Nc899xzLly+nVq1aumigiKigJPy2bdtG27ZtKVasGHPmzKFv375s3LiRFi1akCuXJvUikkk/DSRsDhw4wLBhwxg4cCAHDhzgn//8Jz179iR//vxBRxORCKSCkpBLT09n/Pjx9OjRg82bN3P33XeTnJxM4cKFg44mIhFMS3wSMu7O7NmzKV26NC1btuSqq67iww8/ZMaMGSonETmpQArKzPKa2Stmts7M1pqZ9lDFmKVLl1K9enXuuOMODh06xCuvvMJHH31EpUqVgo4mIlEiqBnUU8Db7l4EKAWsDSiHZLOvv/6axo0bU65cOVauXMnTTz/N6tWrqV+/vnbmicgfEvZjUGZ2PnAz0AzA3dOAtHDnkOz1448/0r9/f0aMGEGOHDl44okn6NSpExdccEHQ0UQkSgWxSeJvwHbgeTMrBSwB2rn7T79+kpm1AloBXHnllWEPKafm8OHDjBw5kqSkJHbv3k2zZs3o06cPBQoUCDqaiES5IJb4cgFlgdHuXgb4Cehy7JPcfYy7J7h7Qr58+cKdUU4iIyODF198kSJFitChQwcqVKjA8uXLGTdunMpJRLJFEAW1Cdjk7p9mff0KmYUlUeK9996jfPny3H///eTNm5d3332Xt956i+uuuy7oaCISQ8JeUO6+FfjOzH7eZ1wNWBPuHPLHrV69mtq1a1O1alW2bdvGxIkTWbJkCdWrVw86mojEoKD+UPdhYLKZnQV8CTQPKIecgs2bN9OzZ0/GjRtHnjx5GDhwII888ki2XpdJRORYgRSUuy8HEoIYW07dvn37GDx4ME8++SRHjhzhkUceoVu3blx00UVBRxOROKBTHcn/c+TIEZ577jl69erFtm3buO+++0hKSuJvf/tb0NFEJI6ooOQX7s7MmTPp0qUL69ev5+abb2bWrFmUL18+6GgiEod0Lj4B4JNPPuHmm2/m7rvvJkeOHLz++uukpKSonEQkMCqoOPf555/ToEEDEhMT2bhxI88++ywrV66kTp06OjWRiARKS3xxaseOHfTp04fRo0fzpz/9iV69etG+fXvOO++8oKOJiAAqqLhz8OBBhg8fzoABA/jpp59o2bIlvXr14q9//WvQ0UREfkMFFSfS09N54YUX6N69O5s2beLOO+9kwIABFC1aNOhoIiLHpWNQceCdd96hbNmyNG/enMsuu4z333+fmTNnqpxEJKKpoGLY8uXLue2226hRowb79+/npZde+mW3nohIpFNBxaBvv/2Wpk2bUrZsWZYsWcLw4cNZs2YN99xzj3bmiUjU0DGoGLJ7926Sk5N56qmnAOjUqRNdunQhb968AScTEfnjVFAxIC0tjdGjR9O3b1927dpFkyZN6Nu3ry70KCJRTUt8UczdeemllyhatCiPPvooZcuWZenSpUyYMEHlJCJRTwUVpRYsWEDFihW57777OO+883jnnXeYM2cOpUuXDjqaiEi2UEFFmbVr13LXXXdxyy23sHnzZsaPH8/SpUu57bbbgo4mIpKtAisoM8tpZsvM7I2gMkSTrVu30rp1a0qWLElKSgrJycls2LCBpk2bkjNnzqDjiYhkuyA3SbQD1gLnB5gh4u3fv58nn3ySwYMHc/jwYdq2bUu3bt3Ily9f0NFEREIqkBmUmRUA7gCeC2L8aHD06FHGjBlDoUKF6NWrF7Vq1WLt2rU89dRTKicRiQtBzaCGA52APAGNH7HcnTfeeIPOnTuzdu1aKlWqxKuvvkrFihWDjiYiElZhn0GZWW1gm7svOcnzWplZqpmlbt++PUzpgrV48WKqVKnCnXfeSXp6Oq+++ioffPCByklE4lIQS3yVgDvN7GtgKlDVzCYd+yR3H+PuCe6eEOtLWl9++SX33Xcf5cuXZ+3atYwePZpVq1ZRt25dnZpIROJW2AvK3R939wLuXhC4D5jv7o3DnSMS7Ny5k3//+98UKVKEWbNm0aNHDz7//HNat25N7ty5g44nIhIoneooAIcOHWLEiBH079+fffv20aJFC3r16sVll10WdDQRkYgRaEG5ewqQEmSGcMrIyGDy5Ml069aNb7/9ltq1azNgwACKFy/v5QuEAAAH+ElEQVQedDQRkYijM0mEydy5cylXrhwPPPAA+fLlY/78+cyaNUvlJCJyAiqoEFu5ciU1atTg1ltvZffu3UyZMoVFixZRpUqVoKOJiEQ0FVSIbNq0iebNm1O6dGkWLVrEk08+ybp162jYsCE5cuhtFxE5GW2SyGZ79uxh4MCBDBs2jIyMDNq3b88TTzzBhRdeGHQ0EZGoooLKJmlpaTz77LP06dOHHTt20KhRI/r160fBggWDjiYiEpW01nSG3J1XXnmF4sWL88gjj3DdddexZMkSJk2apHISETkDKqgz8NFHH3HDDTfQoEEDzj77bGbPns3cuXMpW7Zs0NFERKKeCuo0rF+/nnr16nHjjTfy7bffMnbsWJYvX07NmjV1aiIRkWyigvoDfvjhB9q2bUvx4sWZO3cu/fr1Y8OGDTz44IO6aKCISDbTJolT8NNPPzFs2DAGDhzIoUOHaN26NT169CB//vxBRxMRiVkqqN+Rnp7O+PHj6dGjB5s3b6ZevXokJydz7bXXBh1NRCTmaYnvONyd2bNnU6pUKVq2bMlVV13FRx99xPTp01VOIiJhooI6xpIlS6hWrRp33HEHaWlpTJ8+/ZfdeiIiEj4qqCxff/01jRo1IiEhgVWrVjFy5EhWr15NvXr1tDNPRCQAcX8MateuXfTv35+nn36anDlz0rVrVzp16sT5558fdDQRkbgWtwV1+PBhRo4cSVJSErt376Z58+b07t2bAgUKBB1NREQIYInPzK4ws/fMbK2ZrTazduEcPyMjgylTplCkSBE6dOhAxYoVWbFiBWPHjlU5iYhEkCCOQR0F2rt7UaAi0NbMioVj4Pfee4/y5cvTqFEjLrzwQubOncvs2bMpWbJkOIYXEZE/IOwF5e5b3H1p1uf7gLXA5aEcc/Xq1dSuXZuqVauyfft2XnjhBVJTU6lWrVoohxURkTMQ6DEoMysIlAE+Pc5jrYBWAFdeeeVpj3H06FFq1arF3r17GTx4MA899BBnn332ab+eiIiER2AFZWbnAdOBR91977GPu/sYYAxAQkKCn+44uXLl4qWXXqJQoUJcdNFFp51XRETCK5CCMrPcZJbTZHefEerxKlasGOohREQkmwWxi8+AscBadx8a7vFFRCQ6BLGLrxLQBKhqZsuzPmoFkENERCJY2Jf43P1DQOcOEhGR36Vz8YmISERSQYmISERSQYmISERSQYmISERSQYmISESKi4JauBCSkzNvRUQkOsT89aAWLoRq1SAtDc46C+bNg8TEoFOJiMjJxPwMKiUls5zS0zNvU1KCTiQiIqci5guqcuXMmVPOnJm3lSsHnUhERE5FzC/xJSZmLuulpGSWk5b3RESiQ8wXFGSWkopJRCS6xPwSn4iIRCcVlIiIRCQVlIiIRCQVlIiIRCQVlIiIRCQVlIiIRCRz96AznJSZbQe+OcOXuRjYkQ1xYoXej9/S+/Ffei9+S+/Hb2XH+3GVu+c72ZOioqCyg5mluntC0Dkihd6P39L78V96L35L78dvhfP90BKfiIhEJBWUiIhEpHgqqDFBB4gwej9+S+/Hf+m9+C29H78Vtvcjbo5BiYhIdImnGZSIiEQRFZSIiESkmC8oM6thZuvN7HMz6xJ0nqCZ2Tgz22Zmq4LOEjQzu8LM3jOztWa22szaBZ0pSGZ2tpktMrMVWe9H76AzRQIzy2lmy8zsjaCzBM3Mvjazz8xsuZmlhny8WD4GZWY5gQ3ArcAmYDHQ0N3XBBosQGZ2M7AfmOjuJYLOEyQzuxS41N2XmlkeYAlQN17/+zAzA8519/1mlhv4EGjn7p8EHC1QZvYYkACc7+61g84TJDP7Gkhw97D84XKsz6DKA5+7+5fungZMBe4KOFOg3H0BsCvoHJHA3be4+9Ksz/cBa4HLg00VHM+0P+vL3Fkfsfsb7CkwswLAHcBzQWeJR7FeUJcD3/3q603E8Q8gOTEzKwiUAT4NNkmwspazlgPbgHfdPa7fD2A40AnICDpIhHBgjpktMbNWoR4s1gvKjnNfXP9GKP+fmZ0HTAcedfe9QecJkrunu3tpoABQ3szidhnYzGoD29x9SdBZIkgldy8L1ATaZh0yCJlYL6hNwBW/+roAsDmgLBKBso61TAcmu/uMoPNECnffDaQANQKOEqRKwJ1Zx12mAlXNbFKwkYLl7puzbrcBr5J5GCVkYr2gFgOFzOxqMzsLuA94PeBMEiGyNgWMBda6+9Cg8wTNzPKZWd6sz88BqgPrgk0VHHd/3N0LuHtBMn92zHf3xgHHCoyZnZu1mQgzOxe4DQjpbuCYLih3Pwo8BLxD5gHwae6+OthUwTKzF4GFQGEz22RmLYLOFKBKQBMyfzNenvVRK+hQAboUeM/MVpL5y9277h73W6vlF5cAH5rZCmAR8Ka7vx3KAWN6m7mIiESvmJ5BiYhI9FJBiYhIRFJBiYhIRFJBiYhIRFJBiYhIRFJBiYhIRFJBiYhIRFJBiQTMzK43s5VZ12M6N+taTHF7DjyRn+kPdUUigJn1A84GzgE2uXtywJFEAqeCEokAWeeKXAwcAm5w9/SAI4kETkt8IpHhL8B5QB4yZ1IicU8zKJEIYGavk3lJh6vJvAz9QwFHEglcrqADiMQ7M3sAOOruU8wsJ/CxmVV19/lBZxMJkmZQIiISkXQMSkREIpIKSkREIpIKSkREIpIKSkREIpIKSkREIpIKSkREIpIKSkREItL/AV4wAXClY9zwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model is y = 3x+2\n",
    "np.random.seed(123123)\n",
    "x = np.array([0, 1, 2, 3, 4, 5])\n",
    "y = 3*x+2\n",
    "# Add the noise\n",
    "t = y + 5*(np.random.rand(6)-0.5)\n",
    "xyplot(x,t,x2=x,y2=y,title=r'$y=3x+2$',fname='simple-linear.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data (blue points), the trend (black line), and the residuals (red lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'k-')\n",
    "plt.plot(x,t,'b.')\n",
    "for i,j in enumerate(x):\n",
    "    plt.plot([j,j],[y[i],t[i]],'r-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()\n",
    "plt.title(r'$y=3x+2+\\epsilon$')\n",
    "plt.savefig('simple-linear-residuals.pdf',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce a working example that we will refer to frequently. We generate data from an underlying function $y=\\sin(2\\pi x)$ and investigate how different methods are able to learn the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the function using a lambda expression because it is very simple\n",
    "f = lambda x: np.sin(2*np.pi*x)\n",
    "# Now we generate two datasets. One is defined on a high-resolution x-grid so we can plot the trend. The other is a lower-resolution sampling\n",
    "# The trend line\n",
    "x0 = np.linspace(-1,1,1000)\n",
    "y0 = f(x0) # underlying function\n",
    "# Low-res subsampling\n",
    "x = np.linspace(-1,1,10)\n",
    "y = f(x)\n",
    "# Plot both\n",
    "xyplot(x,y,x2=x0,y2=y0,title=r'$y=sin(2\\pi x)$',fname='sin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a naive fit of different degree of polynomial to the data, using the normal equations\n",
    "$$\\mathbf{\\Phi}^\\mathrm{T}\\mathbf{\\Phi}\\mathbf{w} = \\mathbf{\\Phi}^\\mathrm{T}\\mathbf{y}$$\n",
    "where $\\mathbf{\\Phi}_{ij} = \\phi_j(x_i)$, basis function $\\phi_j$ evaluated at data point $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum degree of fit\n",
    "M = 10\n",
    "# Empty list to record the RMS errors\n",
    "rsq = []\n",
    "# Empty list to record the weights for each regression run\n",
    "weights = []\n",
    "# For each degree of polynomaial fit\n",
    "for i in range(0,M):\n",
    "    # Create the Matrix of basis functions for the sampled data\n",
    "    Phi = np.array([pow(x,j) for j in range(0,i+1)]).transpose()\n",
    "    # Create a high-resolution basis matrix so that we can plot the fitted polynomial\n",
    "    hiPhi = np.array([pow(x0,j) for j in range(0,i+1)]).transpose()\n",
    "    # Solve the normal equations using a standard solver\n",
    "    w = np.linalg.solve(np.matmul(Phi.transpose(),Phi), np.matmul(Phi.transpose(),y))\n",
    "    # record the weights\n",
    "    weights.append(w)\n",
    "    # Compute the estimated values of the data points so we can compute the error\n",
    "    yp = np.matmul(Phi,w)\n",
    "    # compute the RMS error\n",
    "    rsq.append(np.sqrt(np.sum(pow(y-yp,2)/x.size)))\n",
    "    # plot the data and the estimates of the model for the low-res and high-res samplings\n",
    "    xyplot(x, y, x2=x0, y2=y0, x3=x0, y3=np.matmul(hiPhi,w), title='M='+str(i), fname='sin-M'+str(i)+'.pdf')\n",
    "# Plot the error curve\n",
    "plt.figure()\n",
    "plt.plot(rsq,'k.-')\n",
    "plt.xlabel('Degree of fit')\n",
    "plt.ylabel('RMS Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sin-rms.pdf')\n",
    "# Print out the weights\n",
    "for i,w in enumerate(weights):\n",
    "    print(str(i) + ' & ' + ' & '.join(['{:5.2f}'.format(i) for i in w]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add some random noise to the data and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the random noise\n",
    "np.random.seed(123123)\n",
    "y = f(x) + 0.5*np.random.randn(x.size)\n",
    "# Maximum degree of fit\n",
    "M = 10\n",
    "# Empty list to record the RMS errors\n",
    "rsq = []\n",
    "# Empty list to record the weights for each regression run\n",
    "weights = []\n",
    "# For each degree of polynomaial fit\n",
    "for i in range(0,M):\n",
    "    # Create the Matrix of basis functions for the sampled data\n",
    "    Phi = np.array([pow(x,j) for j in range(0,i+1)]).transpose()\n",
    "    # Create a high-resolution basis matrix so that we can plot the fitted polynomial\n",
    "    hiPhi = np.array([pow(x0,j) for j in range(0,i+1)]).transpose()\n",
    "    # Solve the normal equations using a standard solver\n",
    "    w = np.linalg.solve(np.matmul(Phi.transpose(),Phi), np.matmul(Phi.transpose(),y))\n",
    "    # record the weights\n",
    "    weights.append(w)\n",
    "    # Compute the estimated values of the data points so we can compute the error    \n",
    "    yp = np.matmul(Phi,w)\n",
    "    # compute the RMS error\n",
    "    rsq.append(np.sqrt(np.sum(pow(y-yp,2)/x.size)))\n",
    "    # plot the data and the estimates of the model for the low-res and high-res samplings\n",
    "    xyplot(x, y, x2=x0, y2=y0, x3=x0, y3=np.matmul(hiPhi,w), title='M='+str(i), fname='sin-noisy-M'+str(i)+'.pdf')\n",
    "# Plot the error curve\n",
    "plt.figure()\n",
    "plt.plot(rsq,'k.-')\n",
    "plt.xlabel('Degree of fit')\n",
    "plt.ylabel('RMS Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sin-noisy-rms.pdf')\n",
    "# Print out the weights\n",
    "for w in weights:\n",
    "    print(' & '.join(['{:5.2f}'.format(i) for i in w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate that add additional data points changes the outcome and the model no longer overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "x1 = np.linspace(-1,1,50)\n",
    "y1 = f(x1) + 0.5*np.random.randn(x1.size)\n",
    "# Maximum degree of fit\n",
    "M = 10\n",
    "# Empty list to record the RMS errors\n",
    "rsq = []\n",
    "# Empty list to record the weights for each regression run\n",
    "weights = []\n",
    "# For each degree of polynomaial fit\n",
    "for i in range(0,M):\n",
    "    # Create the Matrix of basis functions for the sampled data\n",
    "    Phi = np.array([pow(x1,j) for j in range(0,i+1)]).transpose()\n",
    "    # Create a high-resolution basis matrix so that we can plot the fitted polynomial\n",
    "    hiPhi = np.array([pow(x0,j) for j in range(0,i+1)]).transpose()\n",
    "    # Solve the normal equations using a standard solver\n",
    "    w = np.linalg.solve(np.matmul(Phi.transpose(),Phi), np.matmul(Phi.transpose(),y1))\n",
    "    # record the weights\n",
    "    weights.append(w)\n",
    "    # Compute the estimated values of the data points so we can compute the error    \n",
    "    yp = np.matmul(Phi,w)\n",
    "    # compute the RMS error\n",
    "    rsq.append(np.sqrt(np.sum(pow(y1-yp,2)/x.size)))\n",
    "    # plot the data and the estimates of the model for the low-res and high-res samplings\n",
    "    xyplot(x1, y1, x2=x0, y2=y0, x3=x0, y3=np.matmul(hiPhi,w), title='M='+str(i), fname='sin-noisy-highres-M'+str(i)+'.pdf')\n",
    "# Plot the error curve\n",
    "plt.figure()\n",
    "plt.plot(rsq,'k.-')\n",
    "plt.xlabel('Degree of fit')\n",
    "plt.ylabel('RMS Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sin-noisy-highres-rms.pdf')\n",
    "# Print out the weights\n",
    "for w in weights:\n",
    "    print(' & '.join(['{:5.2f}'.format(i) for i in w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to prevent overfitting is to employ a regularisation method. Here, we use $L_2$ regularisation, which employs the loss function\n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{w}) = \\left(\\mathbf{y}-\\mathbf{\\Phi}\\mathbf{w}\\right)^\\mathrm{T}\\left(\\mathbf{y}-\\mathbf{\\Phi}\\mathbf{w}\\right) + \\lambda\\mathbf{w}^\\mathrm{T}\\mathbf{w}$$\n",
    "\n",
    "which is minimised by solving\n",
    "$$\\left(\\mathbf{\\Phi}^\\mathrm{T}\\mathbf{\\Phi}-\\lambda\\mathbf{I}\\right)\\mathbf{w} = \\mathbf{\\Phi}^\\mathrm{T}\\mathbf{y}$$\n",
    "\n",
    "We will see here that whilst too little regularisation leads to overfitting, too much leads to a loss of expressive power in the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with random noise\n",
    "np.random.seed(12345)\n",
    "y = f(x) + 0.5*np.random.randn(x.size)\n",
    "# Empty lists to store results\n",
    "rsq = []\n",
    "weights = []\n",
    "# Create a basis matrix for a high-order fit so we can assess overfitting.\n",
    "Phi = np.array([pow(x,i) for i in range(0,10)]).transpose()\n",
    "# Basis for high-order, high res fit so we can plot the fit.\n",
    "hiPhi = np.array([pow(x0,i) for i in range(0,10)]).transpose()\n",
    "# Define the values of the regularisation parameter \n",
    "loglambda = [-6, -5, -4, -3, -2, -1]\n",
    "for l in loglambda:\n",
    "    # Solve the normal equations using a standard solver\n",
    "    w = np.linalg.solve(np.matmul(Phi.transpose(),Phi)-pow(10,l)*np.eye(y.size), np.matmul(Phi.transpose(),y))\n",
    "    # record the weights\n",
    "    weights.append(w)\n",
    "    # Compute the estimated values of the data points so we can compute the error\n",
    "    yp = np.matmul(Phi,w)\n",
    "    # compute the RMS error\n",
    "    rsq.append(np.sqrt(np.sum(pow(y-yp,2)/x.size)))\n",
    "    # plot the data and the estimates of the model for the low-res and high-res samplings\n",
    "    xyplot(x, y, x2=x0, y2=y0, x3=x0, y3=np.matmul(hiPhi,w), title=r'$\\log(\\lambda)$='+str(l), fname='sin-noisy-L2-L'+str(l)+'.pdf')\n",
    "# Plot the error curve\n",
    "plt.figure()\n",
    "plt.plot(loglambda,rsq,'k.-')\n",
    "plt.xlabel(r'$\\log(\\lambda)$')\n",
    "plt.ylabel('RMS Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sin-noisy-L2-rms.pdf')\n",
    "for w in weights:\n",
    "    print(' & '.join(['{:5.2f}'.format(i) for i in w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try some validation. Let's generate a new 20-point dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123123)\n",
    "x = np.atleast_2d(np.random.permutation(np.linspace(-1,1,20)))\n",
    "y = f(x) + 0.25*np.random.randn(x.size)\n",
    "# High-resolution dataset\n",
    "xt = np.linspace(-1,1,1000)\n",
    "yt = f(xt)\n",
    "# Combine the x and y coordinates into a single nump array so that we can split them up into the different sets more easily.\n",
    "D = np.concatenate([x.T,y.T],axis=1)\n",
    "xyplot(D[:,0],D[:,1],x2=xt,y2=yt,title='Full Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into Training, Validation and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "TrainSet = D[0:10]\n",
    "ValidationSet = D[10:15]\n",
    "TestSet = D[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models. We will look a polynomials of order 1 to 10\n",
    "# Create empty lists for the results.\n",
    "weights = []\n",
    "train_error = []\n",
    "validation_error = []\n",
    "max_order=10\n",
    "for i in range(max_order):\n",
    "    PhiTrain = np.array([pow(TrainSet[:,0],j) for j in range(0,i+1)]).transpose()\n",
    "    PhiValid = np.array([pow(ValidationSet[:,0],j) for j in range(0,i+1)]).transpose()\n",
    "    # Train the model\n",
    "    w = np.linalg.solve(np.matmul(PhiTrain.transpose(),PhiTrain), np.matmul(PhiTrain.transpose(),TrainSet[:,1]))\n",
    "    print(w)\n",
    "    weights.append(w)\n",
    "    # Compute the error on the training set\n",
    "    train_error.append(np.sqrt(np.average(pow(TrainSet[:,1]-np.matmul(PhiTrain,w),2))))\n",
    "    # Compute the error on the validation set\n",
    "    validation_error.append(np.sqrt(np.average(pow(ValidationSet[:,1]-np.matmul(PhiValid,w),2))))\n",
    "    plt.figure()\n",
    "    # Plot the training data\n",
    "    plt.plot(TrainSet[:,0],TrainSet[:,1],'r.')\n",
    "    # Plot the validation data\n",
    "    plt.plot(ValidationSet[:,0],ValidationSet[:,1],'b.')\n",
    "    # Plot the real trend line\n",
    "    plt.plot(xt,yt,'k-')\n",
    "    # Plot the high-res fitted curve\n",
    "    plt.plot(xt,np.matmul(np.array([pow(xt,j) for j in range(0,i+1)]).transpose(),w),'r-')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('M='+str(i))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Validation-M='+str(i)+'.pdf')\n",
    "# plot the training and validation errors\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,max_order-1,max_order),train_error, 'k.-')\n",
    "plt.plot(np.linspace(0,max_order-1,max_order),validation_error, 'b.-')\n",
    "plt.xlabel('Degree of fit')\n",
    "plt.ylabel('RMS Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Validation-Errors.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of the training error and the validation error suggests that $M=5$ is the best choice for the polynomila order: adding higher order terms does not change the error very much, and so we apply Ockham's razor and select the simplest model. There is one final task: to compute the error on the unseen test set to see if we have really learned the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal fit is M=5, compute test error for this\n",
    "Phi = np.array([pow(TestSet[:,0],j) for j in range(0,6)]).transpose()\n",
    "test_error = np.sqrt(np.average(pow(TestSet[:,1]-np.matmul(Phi,weights[5]),2)))\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is comparable to the validation error - we would not expect it to be quite as low because the test data is unseen. Note that other order fits may fit the test data even more accurately - but this is a consequence of the relatively small sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
